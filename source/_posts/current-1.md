---
title: java 并发（一）JMM
date: 2021-01-10 12:34:30
tags: [并发]
---

# 一、基础


### 现代计算机架构

1. 计算机架构

硬件架构的简单图示：
![现代计算机架构](/image/java/cn/jsjjg.png)

+	内存（交换数据）：一个计算机还包含一个主存。所有的CPU都可以访问主存。主存通常比CPU中的缓存大得多。
+	高速缓存cache（缓存硬盘数据）：由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以添加了读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲。每个CPU可能有一个CPU缓存层，一些CPU还有多层缓存。
+	多CPU（数据运算）：一个现代计算机通常由两个或者多个CPU。其中一些CPU还有多核。从这一点可以看出，在一个有两个或者多个CPU的现代计算机上同时运行多个线程是可能的。
	+	CPU寄存器：每个CPU都包含一系列的寄存器，它们是CPU内内存的基础。CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器的速度远大于主存。

+	运行原理
	+	当需要运行程序时，数据从硬盘加载到内存中；
	+	内存准备完毕后会将数据加载到高速缓存cache，以弥补存储设备与处理器运算速度的差距；
	+	CPU将缓存中部分内容读到它的内部寄存器中，然后在寄存器中执行操作


2. 多线程环境下需要解决的问题

缓存一致性问题：在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也引入了新的问题：缓存一致性（CacheCoherence）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况。这种情况下，又需要以哪个处理器为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly及DragonProtocol等等。

![缓存一致性](/image/java/cn/cache.png)

指令重排序问题：为了使处理器内部单元可以高效使用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致。因此，如果存在一个计算任务依赖另一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。

Java内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所有的线程栈和堆都分布在主内存中。部分线程栈和堆可能有时候会出现在CPU缓存中和CPU内部的寄存器中。


### JMM

1. 什么是JMM

JMM即为JAVA 内存模型（java memory model）。因为在不同的硬件生产商和不同的操作系统下，内存的访问逻辑有一定的差异，结果就是当你的代码在某个系统环境下运行良好，并且线程安全，但是换了个系统就出现各种问题。Java内存模型，就是为了屏蔽系统和硬件的差异，让一套代码在不同平台下能到达相同的访问结果。JMM从java 5开始的JSR-133发布后，已经成熟和完善起来。

2. JMM结构

JMM结构不是一个实际的架构，是一个抽象的结构。在JMM中，有主存和私有的本地内存两种。

主存是实际存在的，存放线程的共享变量;变量包括实例字段、静态字段、构成数组对象的元素，但不包括局部变量和方法参数。

本地内存是JMM的一个抽象概念，并不真实存在，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化；本地内存中存储了该线程以读/写共享变量的拷贝副本。

![JMM结构](/image/java/cn/jmm-str.png)

3. JMM模型下的线程间通信

线程间通信必须要经过主内存。如果线程A与线程B之间要通信的话，必须要经历下面2个步骤：

+	线程A把本地内存A中更新过的共享变量刷新到主内存中去。
+	线程B到主内存中去读取线程A之前已更新过的共享变量。

![线程通讯](/image/java/cn/thread-msg.png)


线程对变量所有操作都只能在工作内存中进行，不能直接读写主内存。每个线程无法直接访问其他线程的工作内存，因此线程间变量值的传递需要依靠主内存来完成。


4. JMM数据操作类型

为了支持变量从主内存拷贝到工作内存、从工作内存同步到主存，而JMM提供了八种主存和本地主存之间交互的操作，这八种操作都具有原子性。

操作的具体内容如下

+	read（读取）： 作用于主内存，将主内存中的变量值传递到工作内存，以便随后的load操作使用。
+	laod（载入）： 作用于工作内存，将read操作从主内存中获取到的变量值放入工作内存的变量副本中。
+	use（使用）： 作用于工作内存，将工作内存中的变量值传递给执行引擎。每当JVM遇到一条使用变量的字节码指令时，执行此操作。
+	assign（赋值）： 作用于工作内存，执行引擎将接收到的值赋给工作内存中的变量。每当JVM遇到一条给变量赋值的字节码指令时，执行此操作。
+	store（存储）： 作用于工作内存，将工作内存中的变量值同步回主内存，以便随后的write操作使用。
+	write（写入）： 作用于主内存，将store操作从工作内存中获取到的变量值放入主内存的变量中。
+	lock（锁定）： 作用于主内存，将主内存中的变量标识为一个线程独占状态。
+	unlock（解锁）： 作用于主内存，将主内存中被锁定的变量解锁。


### JMM设计的目的

在并发的环境下，内存模型为了屏蔽系统和硬件的差异，需要考虑数据的原子性、可见性、有序性。而Java为此对相对应的关键字进行了封装。

1. 原子性

JMM为了保证原子性提供了变量操作read、load、use、assign、store、write等6个数据操作，虽然存在long和double的特例，但基本可以忽律不计。如果需要更大范围的控制，lock和unlock也可以满足需求。但是虚拟机基于这两个操作提供了monitorenter和monitorexit这两个字节码指令，而synchronized底层就是在调用这两个字节码指令。

2. 可见性

可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。volatile正是为了保证可见性而设计出来的，使用volatile修饰的共享变量进行写操作的时候，会多出Lock前缀的指令，会进行以下两个操作
+	将当前处理器缓存行数据刷写到系统主内存（更新主存）
+	刷回主存的操作会使其它CPU缓存中缓存了该内存地址的数据无效（其余副本无效）

这样就保证了缓存的一致性。除了volatile，synchronized和final也可以实现可见性。

synchronized关键字是通过unlock之前必须把变量同步回主内存来实现的。

final则是在初始化后就不会更改，所以只要在初始化过程中没有把this指针传递出去也能保证对其他线程的可见性。

3. 有序性

线程内的操作一般是有序的，表现为串行；而对于另一个线程来说，所有的操作都是无序的，即指令存在重排序、主内存和工作内存直接同步存在延迟。保证有序性的关键字有volatile和 synchronized。

volatile禁止了指令重排序。

而synchronized则由“一个变量在同一时刻只能被一个线程对其进行lock操作”来保证。synchronized对于三种特性都是支持的，但是因此性能较低。

总的来说，了解内存模型，可以加深我们对于Java多线程的理解。

### concurrent包

在JDK1.5之前，Java中要进行业务并发时，通常需要有程序员独立完成代码实现，Java提供了wait()、notify()和synchronized等方式实现并发。但是，在编写对应代码时需要考虑性能、死锁、公平性、资源管理以及如何避免线程安全性方面带来的危害。在JDK1.5之后，提供了java.util.concurrent工具包简化并发工作，将有效的减少竞争条件（race conditions）和死锁线程。

***concurrent体系划分***

![concurrent包体系划分](/image/current/currentjg.png)

***

# 二、重排序

重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。只要重排序保证了不会影响本线程的结果，就不能保证它的操作按照程序的既定顺序运行——即便重排序会影响其它线程的结果。


### 重排序流程

从源码到最终指令序列的流程如下：

![从源码到最终指令序列](/image/java/cn/mem-resort.png)

+	编译器重排序
	+	编译器优化的重排序：编译器不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。JMM对于编译器重排序规则会禁止特定类型的编译器重排序。
+	处理器重排序
	+	指令级并行的重排序：现代处理器采用指令级并行技术（Instruction-Level-Parallelism，ILP）将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应及其指令的执行顺序。
	+	内存系统的重排序：处理器使用缓存和读/写缓冲区，使得加载和存储的操作看起来在乱序执行。

对于处理器重排序，JMM的处理器重排序会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，以禁止特定类型的处理器重排序。

 
### 重排序规则

1. as-if-serial规则（结果不变）

as-if-serial是指

+	不管怎么进行指令重排序,单线程内程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。
+	为了遵守as-if-serial语义, 编译器和处理器不会对存在数据依赖关系的操作做重排序, 因为这种重排序会改变执行结果. 但是, 如果操作之间不存在数据依赖关系, 这些操作就可能被编译器和处理器重排序.

2. happens-before规则

重排序流程严重影响了实际开发者并发编程的效率，JMM在上层提供了六条规则，便于我们理解内存可见性问题。具体内容如下：
+	程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
+	监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
+	volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
+	传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
+	start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。
+	join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。
+	程序中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。
+	对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。


3. as-if-serial与happens-before的区别

as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。



### 内存屏障

内存屏障，也称内存栅栏，内存栅障，屏障指令等， 是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。
 
编译器和处理器必须同时遵守重排规则。多核处理器需使用内存屏障指令来确保一致性。即使编译器优化掉了一个字段访问（因为一个读入的值未被使用），需要产生内存屏障，就像这个访问仍然需要保护。


***类型***

 ![内存屏障类型](/image/current/ncpz.png)
+	写内存屏障（Store Memory Barrier）：处理器将存储缓存值写回主存（阻塞方式）。
+	读内存屏障（Load Memory Barrier）：处理器，处理失效队列（阻塞方式）。
+	lock：解锁时，jvm会强制刷新cpu缓存，导致当前线程更改，对其他线程可见。
+	volatile：标记volatile的字段，在写操作时，会强制刷新cpu缓存，标记volatile的字段，每次读取都是直接读内存。
+	final：即时编译器在final写操作后，会插入内存屏障，来禁止重排序，保证可见性


### 三. 参考文章

> [Java内存模型（JMM）总结](https://zhuanlan.zhihu.com/p/29881777)