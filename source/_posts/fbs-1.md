---
title: 分布式（一）分布式缓存
date: 2020-07-02 16:18:43
tags: [分布式]
---

分布式缓存是为了解决数据库服务器和WEB服务器的瓶颈，加快访问速度，将数据查询的压力分摊到其它的站点上。

### 1. 缓存

缓存指将需要频繁访问的数据存放在内存中以加快用户访问速度的一种技术。

缓存分`进程级缓存`和`分布式缓存`.
+	进程级缓存指将数据缓存在服务内部，通过Map、List等结构实现存储；
+	分布式缓存指将缓存数据单独存放在分布式系统中，以便于缓存的统一管理和存取。
+	常用的分布式缓存系统有Ehcache、Redis和Memcached。

##### 2. 分布式缓存的设计

分布式缓存是相对于传统的进程内缓存而言的，对于传统的单点Web系统一般使用进程内缓存即可，而在微服务架构下往往需要一个分布式缓存来实现跨服务的缓存系统。一个微服务系统的分布式缓存如下：

![分布式缓存](/image/fbs/microservice-fbsjg.png)

### 2. 数据库存储方案

![主流数据库存储方案](/image/fbs/maindb.png)



### 3. Redis

##### 3.1 原理

Redis是一个开源（BSD许可）的内存中的数据结构存储系统，可以用作数据库、缓存和消息中间件，支持多种类型的数据结构，支持的基本类型如下：
+	String（字符串）、Hash（散列）、List（列表）、Set（集合）、ZSet（有序集合）
+	Bitmap（位图）、HyperLogLog（超级日志）和Geospatial（地理空间）。

Redis内置了复制、Lua脚本、LRU驱动事件、事务和不同级别的磁盘持久化，并通过Redis哨兵（Sentinel）模式和集群模式（Cluster）提供高可用性（High Availability）。

Redis还支持分布式事务、数据分片、数据持久化等功能，是分布式系统中不可或缺的内存数据库服务。

##### 3.2 Redis管道

Redis是基于请求/响应协议的TCP服务。在客户端向服务器发送一个查询请求后，需要监听Socket的返回，该监听过程一直阻塞，直到服务器有结果返回。

由于Redis集群是部署在多个服务器上的，所以Redis的请求/响应模型在每次请求时都要跨网络在不同的服务器之间传输数据，这样每次查询都存在一定的网络延迟（服务器之间的网络延迟一般在20ms左右）。由于服务器一般采用多线程处理业务，并且内存操作效率很高，所以如果一次请求延迟20ms，则多次请求的网络延迟会不断累加。

在分布式环境下，Redis的性能瓶颈主要体现在网络延迟上。而Redis的管道技术指在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应,大大提高了服务器的吞吐量。

两者的请求流程图如下：

![主流数据库存储方案](/image/fbs/redis-pipe.png)



### 4. 分布式缓存业务实现的实际问题

分布式缓存设计的核心问题是：
+	以哪种方式进行缓存预热和缓存更新
+	如何优雅解决缓存雪崩、缓存穿透、缓存降级等问题

##### 4.1 缓存术语

`缓存预热`：指在用户请求数据前先将数据加载到缓存系统中，用户查询事先被预热的缓存数据，以提高系统查询效率。
+	缓存预热一般有系统启动加载、定时加载等方式

`缓存更新`：指在数据发生变化后及时将变化后的数据更新到缓存中。
+	更新策略
	+	定时更新：定时将底层数据库内的数据更新到缓存中，该方法比较简单，适合需要缓存的数据量不是很大的应用场景。
	+	过期更新：定时将缓存中过期的数据更新为最新数据并更新缓存的过期时间。
	+	写请求更新：在用户有写请求时先写数据库同时更新缓存，这适用于用户对缓存数据和数据库的数据有实时强一致性要求的情况。
	+	读请求更新：在用户有读请求时，先判断该请求数据的缓存是否存在或过期，如果不存在或已过期，则进行底层数据库查询并将查询结果更新到缓存中，同时将查询结果返回给用户。

`缓存雪崩`：同一时刻由于大量缓存失效，导致大量原本应该访问缓存的请求都去查询数据库，而对数据库的CPU和内存造成巨大压力，严重的话会导致数据库宕机
+	解决方案
	+	请求加锁：对于并发量不是很多的应用，使用请求加锁排队的方案防止过多请求数据库
	+	失效更新：为每一个缓存数据都增加过期标记来记录缓存数据是否失效，如果缓存标记失效，则更新数据缓存
	+	设置不同的失效时间：为不同的数据设置不同的缓存失效时间，防止在同一时刻有大量的数据失效。

`缓存穿透`：指由于缓存系统故障或者用户频繁查询系统中不存在（在系统中不存在，在自然数据库和缓存中都不存在）的数据，而这时请求穿过缓存不断被发送到数据库，导致数据库过载，进而引发一连串并发问题。
+	解决方案
	+	布隆过滤器：指将所有可能存在的数据都映射到一个足够大的Bitmap中，在用户发起请求时首先经过布隆过滤器的拦截，一个一定不存在的数据会被这个布隆过滤器拦截，从而避免对底层存储系统带来查询上的压力
	+	null策略：指如果一个查询返回的结果为null（可能是数据不存在，也可能是系统故障），我们仍然缓存这个null结果，但它的过期时间会很短，通常不超过 5分钟；在用户再次请求该数据时直接返回null，而不会继续访问数据库，从而有效保障数据库的安全。其实cachenull策略的核心原理是：在缓存中记录一个短暂的（数据过期时间内）数据在系统中是否存在的状态，如果不存在，则直接返回null，不再查询数据库，从而避免缓存穿透到数据库上。

`缓存降级`：指由于访问量剧增导致服务出现问题（如响应时间慢或不响应）时，优先保障核心业务的运行，减少或关闭非核心业务对资源的使用
	+	服务降级策略
		+	写降级：在写请求增大时，可以只进行Cache的更新，然后将数据异步更新到数据库中，保证最终一致性即可，即将写请求从数据库降级为Cache。
		+	读降级：在数据库服务负载过高或数据库系统故障时，可以只对Cache进行读取并将结果返回给用户，在数据库服务正常后再去查询数据库，即将读请求从数据库降级为Cache。这种方式适用于对数据实时性要求不高的场景，保障了在系统发生故障的情况下用户依然能够访问到数据，只是访问到的数据相对有延迟


##### 4.2 缓存淘汰策略

+	FIFO（First In FirstOut，先进先出）：判断被存储的时间，离目前最远的数据优先被淘汰。
+	LRU（Least RecentlyUsed，最近最少使用）：判断缓存最近被使用的时间，距离当前时间最远的数据优先被淘汰。
+	LFU（Least FrequentlyUsed，最不经常使用）：在一段时间内，被使用次数最少的缓存优先被淘汰。


